# Linear Algebra

The study of vectors, matrices, and linear transformations.

## Overview

Linear algebra is fundamental to nearly every area of mathematics and science. It provides tools for solving systems of equations, understanding transformations, and analyzing data.

## Core Concepts

### Vectors and Vector Spaces
- Vector addition and scalar multiplication
- Linear independence
- Basis and dimension
- Subspaces

### Matrices
- Matrix operations
- Row reduction and echelon forms
- Determinants
- Inverse matrices

### Linear Transformations
- Kernel and range
- Rank-nullity theorem
- Matrix representation
- Change of basis

### Eigenvalues and Eigenvectors
- Characteristic polynomial
- Diagonalization
- Jordan normal form

### Inner Product Spaces
- Dot product and norms
- Orthogonality
- Gram-Schmidt process
- Orthogonal projections

### Spectral Theory
- Symmetric matrices
- Positive definite matrices
- Singular value decomposition (SVD)

## Applications

- Systems of linear equations
- Computer graphics
- Machine learning
- Quantum mechanics
- Signal processing
- Statistics (PCA, regression)

## Topics to Explore

- [ ] LU decomposition
- [ ] QR decomposition
- [ ] Eigenvalue algorithms
- [ ] Numerical linear algebra
- [ ] Tensor products

## Resources

- "Linear Algebra Done Right" by Sheldon Axler
- "Introduction to Linear Algebra" by Gilbert Strang
- MIT 18.06 Linear Algebra lectures
